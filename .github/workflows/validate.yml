name: Validate

on:
  push:
    branches: [main]
    paths:
      - 'packages/**'
      - 'shared/**'
      - 'dependencies.yaml'
      - '*.md'
      - '.github/**'
  pull_request:
    branches: [main]
    paths:
      - 'packages/**'
      - 'shared/**'
      - 'dependencies.yaml'
      - '*.md'
      - '.github/**'

jobs:


  detect-changes:
    runs-on: ubuntu-latest
    outputs:
      skill_matrix: ${{ steps.changes.outputs.skill_matrix }}
      has_skills: ${{ steps.changes.outputs.has_skills }}
      dashboard_changed: ${{ steps.changes.outputs.dashboard_changed }}

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Determine base ref
        id: base
        run: |
          set -euo pipefail
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            echo "base_sha=${{ github.event.pull_request.base.sha }}" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          base="${{ github.event.before }}"
          if [[ -z "$base" || "$base" == "0000000000000000000000000000000000000000" ]]; then
            base="$(git merge-base HEAD origin/main || git rev-parse HEAD^)"
          fi
          echo "base_sha=$base" >> "$GITHUB_OUTPUT"

      - name: Detect changed paths
        id: filter
        uses: dorny/paths-filter@v3
        with:
          base: ${{ steps.base.outputs.base_sha }}
          ref: ${{ github.sha }}
          filters: |
            shared:
              - 'shared/**'
              - 'dependencies.yaml'
            skill_job_analyzer:
              - 'packages/job-analyzer/**'
            skill_interview_prep:
              - 'packages/interview-prep/**'
            skill_reading_list:
              - 'packages/reading-list/**'
            skill_ideas_capture:
              - 'packages/ideas-capture/**'
            skill_voice_memos:
              - 'packages/voice-memos/**'
            skill_local_rag:
              - 'packages/local-rag/**'
            skill_recipe_manager:
              - 'packages/recipe-manager/**'
            skill_setup_manager:
              - 'packages/setup-manager/**'
            skill_social_media_post:
              - 'packages/social-media-post/**'
            skill_exocortex_mcp:
              - 'packages/exocortex-mcp/**'
            skill_next_skill:
              - 'packages/next-skill/**'
            skill_dashboard:
              - 'packages/dashboard/**'

      - name: Build skill matrix
        id: changes
        env:
          CHANGES: ${{ steps.filter.outputs.changes }}
        run: |
          set -euo pipefail

          skills=()

          if [[ "$CHANGES" == *"shared"* ]]; then
            skills=(job-analyzer interview-prep reading-list ideas-capture voice-memos local-rag recipe-manager setup-manager social-media-post exocortex-mcp next-skill)
          else
            [[ "$CHANGES" == *"skill_job_analyzer"* ]] && skills+=(job-analyzer)
            [[ "$CHANGES" == *"skill_interview_prep"* ]] && skills+=(interview-prep)
            [[ "$CHANGES" == *"skill_reading_list"* ]] && skills+=(reading-list)
            [[ "$CHANGES" == *"skill_ideas_capture"* ]] && skills+=(ideas-capture)
            [[ "$CHANGES" == *"skill_voice_memos"* ]] && skills+=(voice-memos)
            [[ "$CHANGES" == *"skill_local_rag"* ]] && skills+=(local-rag)
            [[ "$CHANGES" == *"skill_recipe_manager"* ]] && skills+=(recipe-manager)
            [[ "$CHANGES" == *"skill_setup_manager"* ]] && skills+=(setup-manager)
            [[ "$CHANGES" == *"skill_social_media_post"* ]] && skills+=(social-media-post)
            [[ "$CHANGES" == *"skill_exocortex_mcp"* ]] && skills+=(exocortex-mcp)
            [[ "$CHANGES" == *"skill_next_skill"* ]] && skills+=(next-skill)
          fi

          if [[ ${#skills[@]} -eq 0 ]]; then
            skills_json="[]"
          else
            # Use jq -c for compact single-line JSON output
            skills_json=$(printf '%s\n' "${skills[@]}" | jq -R . | jq -sc .)
          fi
          
          {
            echo "skill_matrix=$skills_json"
            echo "has_skills=$([[ ${#skills[@]} -gt 0 ]] && echo true || echo false)"
            if [[ "$CHANGES" == *"skill_dashboard"* || "$CHANGES" == *"shared"* ]]; then
              echo "dashboard_changed=true"
            else
              echo "dashboard_changed=false"
            fi
          } >> "$GITHUB_OUTPUT"

          echo "Skill matrix: $skills_json"

  validate:
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.has_skills == 'true'
    strategy:
      matrix:
        skill: ${{ fromJson(needs.detect-changes.outputs.skill_matrix) }}
      fail-fast: false
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: "0.5.5"

      - name: Install system dependencies (local-rag only)
        if: matrix.skill == 'local-rag'
        run: |
          sudo apt-get update
          sudo apt-get install -y tesseract-ocr tesseract-ocr-heb poppler-utils qpdf ghostscript

      - name: Install dependencies
        run: |
          uv venv
          source .venv/bin/activate
          
          uv pip install pyyaml pytest pytest-cov pytest-asyncio
          
          # Install skill dependencies if they exist
          if [ -f "packages/${{ matrix.skill }}/pyproject.toml" ]; then
             uv sync --project "packages/${{ matrix.skill }}"
          elif [ -f "packages/${{ matrix.skill }}/_dev/requirements.txt" ]; then
             uv pip install -r "packages/${{ matrix.skill }}/_dev/requirements.txt"
          fi
      
      - name: Validate skill structure
        run: |
          SKILL_DIR="packages/${{ matrix.skill }}"
          
          # Check required files
          echo "Checking ${{ matrix.skill }}..."
          
          if [ -f "$SKILL_DIR/SKILL.md" ]; then
            echo "‚úÖ SKILL.md exists"
          elif [ "${{ matrix.skill }}" == "exocortex-mcp" ]; then
             echo "‚úÖ exocortex-mcp exempted from SKILL.md check"
          else
            echo "‚ùå Missing SKILL.md (must be in package root)"
            exit 1
          fi
          
          if [ ! -f "$SKILL_DIR/README.md" ] && [ ! -f "$SKILL_DIR/_dev/README.md" ]; then
            echo "‚ö†Ô∏è Missing README.md (recommended)"
          else
            echo "‚úÖ README.md exists"
          fi

          if [ ! -f "$SKILL_DIR/AI_GUIDE.md" ]; then
            echo "‚ö†Ô∏è Missing AI_GUIDE.md (recommended)"
          else
            echo "‚úÖ AI_GUIDE.md exists"
          fi
          
          # Check for version file
          if [ -f "$SKILL_DIR/version.yaml" ] || [ -f "$SKILL_DIR/_dev/version.yaml" ] || [ -f "$SKILL_DIR/pyproject.toml" ]; then
            echo "‚úÖ version.yaml/pyproject.toml exists"
          else
            echo "‚ö†Ô∏è Missing version metadata"
          fi
          
          echo "‚úÖ ${{ matrix.skill }} validation passed"
      
      - name: Validate YAML files
        run: |
          # Use the installed python environment
          uv run python -c "
          import yaml
          import glob
          import sys
          import re

          def parse_yaml_with_frontmatter(content):
              '''Parse YAML that may have frontmatter followed by Markdown.'''
              # Check if file starts with --- (frontmatter pattern)
              if content.startswith('---'):
                  # Find the closing --- marker
                  # Match from after first --- to the next ---
                  match = re.match(r'^---\n(.*?)\n---', content, re.DOTALL)
                  if match:
                      # Only parse the frontmatter YAML portion
                      return yaml.safe_load(match.group(1))
              # If no frontmatter, parse entire file
              return yaml.safe_load(content)

          errors = []
          for f in glob.glob('packages/${{ matrix.skill }}/**/*.yaml', recursive=True):
              try:
                  with open(f) as file:
                      content = file.read()
                      parse_yaml_with_frontmatter(content)
                  print(f'‚úÖ {f}')
              except Exception as e:
                  errors.append(f'‚ùå {f}: {e}')

          if errors:
              for e in errors:
                  print(e)
              sys.exit(1)
          "

      - name: Run Tests
        env:
          # local-rag specific envs
          TOKENIZERS_PARALLELISM: "false"
          LOCAL_RAG_REAL_OCR_DEPS: "1"
          PYTHONPATH: "packages/${{ matrix.skill }}"
        run: |
          TEST_DIR="packages/${{ matrix.skill }}/tests"
          if [ -d "$TEST_DIR" ]; then
            echo "üß™ Running tests for ${{ matrix.skill }}..."
            uv run pytest "$TEST_DIR" --verbose
          else
            echo "‚ö†Ô∏è No tests directory found at $TEST_DIR"
          fi

  validate-dashboard:
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.dashboard_changed == 'true'
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: packages/dashboard/package-lock.json

      - name: Install dependencies
        working-directory: packages/dashboard
        run: npm ci

      - name: Lint
        working-directory: packages/dashboard
        run: npm run lint

      - name: Build
        working-directory: packages/dashboard
        run: npm run build

  lint-scripts:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Check Python syntax
        shell: bash
        run: |
          set -euo pipefail
          shopt -s nullglob

          echo "=== Checking shared scripts ==="
          python -m py_compile shared/scripts/release.py
          python -m py_compile shared/scripts/skill_generator.py
          python -m py_compile shared/scripts/dependency_tracker.py
          python -m py_compile shared/scripts/yaml_utils.py
          python -m py_compile shared/scripts/slug_utils.py
          python -m py_compile shared/scripts/token_estimator.py

          echo "=== Checking job-analyzer scripts ==="
          for f in packages/job-analyzer/scripts/*.py; do
            python -m py_compile "$f"
          done

          echo "=== Checking interview-prep scripts ==="
          for f in packages/interview-prep/scripts/*.py; do
            python -m py_compile "$f"
          done

          echo "=== Checking local-rag modules ==="
          LOCAL_RAG_PATHS=(
            packages/local-rag/local_rag/*.py
            packages/local-rag/local_rag/adapters/*.py
            packages/local-rag/local_rag/ingestion/*.py
            packages/local-rag/local_rag/search/*.py
            packages/local-rag/local_rag/services/*.py
            packages/local-rag/local_rag/storage/*.py
            packages/local-rag/local_rag/utils.py
            packages/local-rag/local_rag/utils/*.py
          )
          for f in "${LOCAL_RAG_PATHS[@]}"; do
            python -m py_compile "$f"
          done

          echo "‚úÖ All Python scripts syntax OK"

  skill-structure-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install pytest pyyaml

      - name: Run skill structure tests
        run: |
          echo "=== Running Skill Structure Validation Tests ==="
          pytest shared/tests/test_skill_structure.py -v --tb=short

  dependency-check:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Need full history for git log comparison

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install pyyaml

      - name: Check dependency status
        id: deps
        run: |
          echo "=== Dependency Status ==="
          python shared/scripts/dependency_tracker.py status | tee deps_output.txt

          # Check if any files need attention
          if grep -q "NEEDS UPDATE\|MISSING" deps_output.txt; then
            echo "needs_update=true" >> "$GITHUB_OUTPUT"
            echo ""
            echo "‚ö†Ô∏è Some files may need updating. Run /refactor to sync."
          else
            echo "needs_update=false" >> "$GITHUB_OUTPUT"
            echo ""
            echo "‚úÖ All dependencies are in sync."
          fi

      - name: Comment on PR (if files need update)
        if: github.event_name == 'pull_request' && steps.deps.outputs.needs_update == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const output = fs.readFileSync('deps_output.txt', 'utf8');

            // Check if we already commented
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number
            });

            const botComment = comments.find(c =>
              c.user.type === 'Bot' && c.body.includes('Dependency Check')
            );

            const body = `‚ö†Ô∏è **Dependency Check**: Some files may need updating.

            <details>
            <summary>View dependency status</summary>

            \`\`\`
            ${output}
            \`\`\`

            </details>

            Run \`/refactor\` in Claude Code to update dependent files before merging.`;

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }


